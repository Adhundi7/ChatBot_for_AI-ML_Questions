There is a continum between memorization and generalization. The extremes is what we are talking about just so we can identify the spectrum. Usually, you fall somewhere in between. With zero information you cannot learn (except zero shot learning where you can learn without a single example, you can generalize to unseen samples even). Between seeing some samples and learning from them and then going to the extreme of generalization where you are able to perform on unseen samples, there is some amount of memorization. If you have a decision boundary seperating, you need to know that one side is apple and the other is orange. That much memory youo need. If it is an extremely simple classifier, the amount of memory you require is less. For far more complex classifier, you need to remember more. So, it depends on the problem and the data that you have. So, it is a combination, for every sample in space you need a label, this is learning the boundary. Not just that, it has learnt the overall distribution of samples. Then, you just need to memorize the regions covered by class A, B so on.